{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70e87eaa",
   "metadata": {
    "id": "70e87eaa"
   },
   "source": [
    "# Partial Neural Network Model Evaluation Notebook\n",
    "\n",
    "This notebook evaluates a Partial Neural Network (PNN) model for predicting strain responses in layered elastic systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc784cc6",
   "metadata": {
    "id": "cc784cc6"
   },
   "source": [
    "## Setup and Dependencies\n",
    "\n",
    "First, we install required packages and import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "uQMlEoAc086C",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20465,
     "status": "ok",
     "timestamp": 1750126821785,
     "user": {
      "displayName": "Urja Giridharan",
      "userId": "03202406529544037479"
     },
     "user_tz": 240
    },
    "id": "uQMlEoAc086C",
    "outputId": "a865b92b-cc75-4fcd-a678-ebbf8e8bea7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch_geometric\n",
      "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m61.4/63.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.15)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.0.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.20.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.4.26)\n",
      "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch_geometric\n",
      "Successfully installed torch_geometric-2.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "766b70a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21555,
     "status": "ok",
     "timestamp": 1750126847667,
     "user": {
      "displayName": "Urja Giridharan",
      "userId": "03202406529544037479"
     },
     "user_tz": 240
    },
    "id": "766b70a7",
    "outputId": "3d311164-ac40-4717-f6e3-e7673d4e47e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39277259-f20e-4f53-9681-4bf3023084ef",
   "metadata": {
    "executionInfo": {
     "elapsed": 19086,
     "status": "ok",
     "timestamp": 1750127939981,
     "user": {
      "displayName": "Urja Giridharan",
      "userId": "03202406529544037479"
     },
     "user_tz": 240
    },
    "id": "39277259-f20e-4f53-9681-4bf3023084ef"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import torch\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_percentage_error,mean_absolute_error\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GATConv\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import logging\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9ddaf1",
   "metadata": {
    "id": "7a9ddaf1"
   },
   "source": [
    "## Data Loading and Preprocessing\n",
    "\n",
    "This section handles the loading of pre-processed data required for model evaluation:\n",
    "\n",
    "- **batched_graph_test**: Contains the test dataset in graph format\n",
    "- **FrameLarge**: Contains the full dataset with material properties and responses\n",
    "- **Section**: Contains the layered structure information\n",
    "- **ZS_new**: Contains the z-coordinates (depth points) for each section\n",
    "- **xs**: Contains the x-coordinates (radial distance points)\n",
    "\n",
    "The data is loaded from pickle files stored in Google Drive, with paths specified in the configuration. Each dataset contains specific information about the pavement structure and its response to loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3Z3zuS1a8hLz",
   "metadata": {
    "executionInfo": {
     "elapsed": 3151,
     "status": "ok",
     "timestamp": 1750127958250,
     "user": {
      "displayName": "Urja Giridharan",
      "userId": "03202406529544037479"
     },
     "user_tz": 240
    },
    "id": "3Z3zuS1a8hLz"
   },
   "outputs": [],
   "source": [
    "def load_pickle(path):\n",
    "    \"\"\"Load data from pickle file.\n",
    "\n",
    "    Args:\n",
    "        path (str): Path to pickle file\n",
    "\n",
    "    Returns:\n",
    "        Loaded data object\n",
    "    \"\"\"\n",
    "    with open(path, 'rb') as fp:\n",
    "        return pickle.load(fp)\n",
    "\n",
    "batched_graph_test_path = '/content/drive/MyDrive/Graph_Neural_Network/PIML-main/data/batched_graph_test.pkl'\n",
    "frame_path = '/content/drive/MyDrive/Graph_Neural_Network/PIML-main/data/frame_large.pkl'\n",
    "section_path = '/content/drive/MyDrive/Graph_Neural_Network/PIML-main/data/section.pkl'\n",
    "ZS_path = '/content/drive/MyDrive/Graph_Neural_Network/PIML-main/data/ZS.pkl'\n",
    "xs_path = '/content/drive/MyDrive/Graph_Neural_Network/PIML-main/data/xs.pkl'\n",
    "model_path = '/content/drive/MyDrive/Graph_Neural_Network/PIML-main/models/GAT_model.pt'\n",
    "\n",
    "\n",
    "batched_graph_test = load_pickle(batched_graph_test_path)\n",
    "FrameLarge = load_pickle(frame_path)\n",
    "Section = load_pickle(section_path)\n",
    "ZS_new = load_pickle(ZS_path)\n",
    "xs = load_pickle(xs_path)\n",
    "checkpoint = torch.load(model_path, map_location='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0134fcc",
   "metadata": {
    "id": "c0134fcc"
   },
   "source": [
    "## Configuration\n",
    "\n",
    "This section defines three main configuration dictionaries that control the model and data generation:\n",
    "\n",
    "### Material Configuration (MATERIAL_CONFIG)\n",
    "- Defines properties of pavement materials (Asphalt Concrete, Base, Subgrade)\n",
    "- Specifies ranges for:\n",
    "  - Thickness (in inches)\n",
    "  - Modulus (in ksi)\n",
    "  - Poisson's ratio\n",
    "  - Number of sublayers\n",
    "- Sets increment steps for sampling material properties\n",
    "\n",
    "### Sampling Configuration (SAMPLING_CONFIG)\n",
    "- Controls data generation parameters:\n",
    "  - Number of points to generate\n",
    "  - Points along depth (z-axis) and radial distance (x-axis)\n",
    "  - Contact radius parameters\n",
    "  - Train/validation/test split indices\n",
    "  - Random seed for reproducibility\n",
    "\n",
    "### Model Configuration (MODEL_CONFIG)\n",
    "- Defines the GAT model architecture:\n",
    "  - Input dimension (5 features)\n",
    "  - Hidden layer dimensions (128, 90)\n",
    "  - Output dimension (3 strain components)\n",
    "  - Number of GAT layers (10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3Cb0G53kzNLW",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1750127963523,
     "user": {
      "displayName": "Urja Giridharan",
      "userId": "03202406529544037479"
     },
     "user_tz": 240
    },
    "id": "3Cb0G53kzNLW"
   },
   "outputs": [],
   "source": [
    "MATERIAL_CONFIG = {\n",
    "    'N_MATERIALS': 3,\n",
    "    'MATERIAL_TYPES': ['AC', 'B', 'SG'],  # AC, base, subbase, subgrade\n",
    "    'SUBLAYER_MAX': [1, 1, 1],  # each material's max sublayers, excluding subgrade\n",
    "    'THICKNESS_RANGE': [[2, 16], [4, 20]],  # thickness range in inches\n",
    "    'MODULUS_RANGE': [[500, 2000], [50, 300], [5, 50]],  # modulus range in ksi\n",
    "    'THICKNESS_INCREMENT': [1, 2, 4],\n",
    "    'MODULUS_INCREMENT': [50, 20, 20, 5],  # increment in modulus sampling\n",
    "    'NU_RANGE': [[0.3, 0.4], [0.2, 0.499], [0.2, 0.499]]  # poissons ratio\n",
    "}\n",
    "\n",
    "SAMPLING_CONFIG = {\n",
    "    'N_POINTS': 1000,  # Number of points\n",
    "    'Z_POINTS': 14,  # points to generate along z\n",
    "    'X_POINTS': 10,  # points to generate along x\n",
    "    'A_RANGE': [4, 4],  # contact radius (in)\n",
    "    'A_POINTS': 1,  # how many contact radii to analyze\n",
    "    'FACTOR': 0.4,\n",
    "    'FILTER': 2,\n",
    "    'SPLIT_IDX': 800,\n",
    "    'TEST_IDX': 900,\n",
    "    'SEED': 42\n",
    "}\n",
    "\n",
    "MODEL_CONFIG = {\n",
    "    'INPUT_DIM': 5,\n",
    "    'HIDDEN_DIM1': 128,\n",
    "    'HIDDEN_DIM': 90,\n",
    "    'OUTPUT_DIM': 3,\n",
    "    'NUM_LAYERS': 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d70e58c7",
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1750127966412,
     "user": {
      "displayName": "Urja Giridharan",
      "userId": "03202406529544037479"
     },
     "user_tz": 240
    },
    "id": "d70e58c7"
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    \"\"\"Set seed for reproducibility across all random operations.\n",
    "\n",
    "    Args:\n",
    "        seed (int): Random seed value\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set the seed at the start\n",
    "set_seed(SAMPLING_CONFIG['SEED'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629488c3",
   "metadata": {
    "id": "629488c3"
   },
   "source": [
    "## Data Generation Functions\n",
    "\n",
    "This section contains functions for generating and processing the layered elastic system data:\n",
    "\n",
    "### generatesection()\n",
    "Generates random pavement sections with realistic material properties:\n",
    "- Creates multiple layers with different materials\n",
    "- Assigns random but realistic values for:\n",
    "  - Layer thicknesses\n",
    "  - Modulus values\n",
    "  - Poisson's ratios\n",
    "- Handles sublayer generation based on thickness constraints\n",
    "- Returns both section properties and a structured DataFrame\n",
    "\n",
    "### generate_query_points()\n",
    "Generates the points where strain will be calculated:\n",
    "- Creates a grid of points in (x,z) space\n",
    "- Maps material properties to each point\n",
    "- Handles boundary conditions between layers\n",
    "- Returns query points and associated properties\n",
    "\n",
    "### remove_strain_z()\n",
    "Filters out sections with unrealistic strain values:\n",
    "- Removes sections where strain exceeds 1500 µε\n",
    "- Normalizes z-coordinates\n",
    "- Returns filtered dataset and updated z-points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "Zih3T0MNzoLs",
   "metadata": {
    "executionInfo": {
     "elapsed": 58,
     "status": "ok",
     "timestamp": 1750127980912,
     "user": {
      "displayName": "Urja Giridharan",
      "userId": "03202406529544037479"
     },
     "user_tz": 240
    },
    "id": "Zih3T0MNzoLs"
   },
   "outputs": [],
   "source": [
    "\n",
    "def generatesection(N,Nmaterial,MaterialType,Sublayermax,Thicknessrange,Modulusrange,\n",
    "                              zpoints,xpoints,Thicknessincrement,ModulusIncrement,nurange,arange,apoints):\n",
    "    \"\"\"Generate layered elastic system sections with random material properties.\n",
    "\n",
    "    Args:\n",
    "        N (int): Number of sections to generate\n",
    "        Nmaterial (int): Number of material types\n",
    "        MaterialType (list): List of material type names\n",
    "        Sublayermax (list): Maximum number of sublayers for each material\n",
    "        Thicknessrange (list): Thickness ranges for each material\n",
    "        Modulusrange (list): Modulus ranges for each material\n",
    "        zpoints (int): Number of points along depth\n",
    "        xpoints (int): Number of points along radial distance\n",
    "        Thicknessincrement (list): Increment steps for thickness\n",
    "        ModulusIncrement (list): Increment steps for modulus\n",
    "        nurange (list): Poisson's ratio ranges\n",
    "        arange (list): Contact radius range\n",
    "        apoints (int): Number of contact radii\n",
    "\n",
    "    Returns:\n",
    "        tuple: (Section dictionary, DataFrame with section properties)\n",
    "    \"\"\"\n",
    "    Section={}\n",
    "    DataFrame={}\n",
    "    columns=['Structure','Pressure','ContactRadius','z','r']\n",
    "    thickCol=[f'H{i}' for i in range(1, sum(Sublayermax))]\n",
    "    columns.extend(thickCol)\n",
    "    modCol=[f'E{i}' for i in range(1, sum(Sublayermax)+1)]\n",
    "    columns.extend(modCol)\n",
    "    nuCol=[f'nu{i}' for i in range(1, sum(Sublayermax)+1)]\n",
    "    columns.extend(nuCol)\n",
    "\n",
    "    for sect in range(N):\n",
    "        Section[sect]={}\n",
    "        DataFrame[sect]=np.zeros(len(columns))\n",
    "        #To generate we have to follow some rules as described above\n",
    "        #First, decide on number of materials\n",
    "        MatNum=np.random.randint(2,Nmaterial+1)\n",
    "\n",
    "        #Then on the thickness\n",
    "        Thick=[]\n",
    "        Poisson=[]\n",
    "        Material=[]\n",
    "        #for each material, we will have poissons ratio and thickness\n",
    "\n",
    "\n",
    "        for i in range(MatNum-1):\n",
    "            T=np.arange(Thicknessrange[i][0],Thicknessrange[i][1]+Thicknessincrement[i],Thicknessincrement[i]) #Increments of 0.5in\n",
    "            P=np.arange(nurange[i][0],nurange[i][1]+0.001,0.05) #Increments of 0.05\n",
    "            Thick.append(np.random.choice(T))\n",
    "            Poisson.append(np.random.choice(P))\n",
    "            Material.append(MaterialType[i])\n",
    "        #For subgrade\n",
    "        P=np.arange(nurange[-1][0],nurange[-1][1]+0.001,0.05)\n",
    "        Poisson.append(np.random.choice(P))\n",
    "        Material.append(MaterialType[-1])\n",
    "\n",
    "        #Round the thickness and poissons ratio\n",
    "        Thick=np.round(Thick,2)\n",
    "        Poisson=np.round(Poisson,3)\n",
    "\n",
    "        #Now we can decide on sublayers\n",
    "        ThickSub=[]\n",
    "        MaterialSub=[]\n",
    "        ModulusSub=[]\n",
    "        PoissonSub=[]\n",
    "        for i in range(MatNum-1):\n",
    "            subs=np.random.randint(1,Sublayermax[i]+1)\n",
    "            M=np.arange(Modulusrange[i][0],Modulusrange[i][1]+ModulusIncrement[i],ModulusIncrement[i]) #increments of 50ksi\n",
    "            Modulus0=np.random.choice(M)\n",
    "\n",
    "            if Thick[i]/subs<1: #if smaller than 1 in, no sublayers\n",
    "                MaterialSub.append(MaterialType[i])\n",
    "                ThickSub.append(Thick[i])\n",
    "                ModulusSub.append(Modulus0)\n",
    "                PoissonSub.append(Poisson[i])\n",
    "\n",
    "                continue\n",
    "\n",
    "            for j in range(subs): #else, divide into sublayers\n",
    "                MaterialSub.append(MaterialType[i])\n",
    "                ThickSub.append(Thick[i]/subs)\n",
    "                PoissonSub.append(Poisson[i])\n",
    "\n",
    "                if j==0: #if we are at the first sublayer assign modulus 0\n",
    "                    ModulusSub.append(Modulus0)\n",
    "                else: #else, assign a smaller modulus\n",
    "                    Modulus0=np.random.uniform(low=Modulusrange[i][0], high=Modulus0)\n",
    "                    ModulusSub.append(Modulus0)\n",
    "\n",
    "        #For subgrade\n",
    "        ModulusSub.append(np.round(np.random.choice(np.arange(Modulusrange[-1][0],Modulusrange[-1][1]+ModulusIncrement[-1],ModulusIncrement[-1]))))\n",
    "        PoissonSub.append(Poisson[-1])\n",
    "        MaterialSub.append('SG')\n",
    "        #Round the values\n",
    "        ThickSub=np.round(ThickSub,2)\n",
    "        ModulusSub=np.round(ModulusSub)\n",
    "        PoissonSub=np.round(PoissonSub,3)\n",
    "\n",
    "        #To create the dictionary\n",
    "        Section[sect]['Material']=Material\n",
    "        Section[sect]['Thickness']=Thick\n",
    "        Section[sect]['Poisson']=Poisson\n",
    "        Section[sect]['MaterialSub']=MaterialSub\n",
    "        Section[sect]['ThicknessSub']=ThickSub\n",
    "        Section[sect]['PoissonSub']=PoissonSub\n",
    "        Section[sect]['ModulusSub']=ModulusSub\n",
    "\n",
    "        #To create the dataframe\n",
    "        t=np.append(Section[sect]['ThicknessSub'], np.zeros(sum(Sublayermax)-1-len(Section[sect]['ThicknessSub'])))\n",
    "        m=np.insert(Section[sect]['ModulusSub'], -1, np.zeros(sum(Sublayermax)-len(Section[sect]['ModulusSub'])))\n",
    "        p=np.insert(Section[sect]['PoissonSub'], -1, np.zeros(sum(Sublayermax)-len(Section[sect]['PoissonSub'])))\n",
    "        DataFrame[sect]=np.append(np.zeros(5),t)\n",
    "        DataFrame[sect][0]=sect+1 #assign structure\n",
    "        DataFrame[sect][1]=80 #assign pressure of 80 psi (9000/np.pi/6**2)\n",
    "        DataFrame[sect]=np.append(DataFrame[sect],m)\n",
    "        DataFrame[sect]=np.append(DataFrame[sect],p)\n",
    "    Frame=pd.DataFrame.from_dict(DataFrame, orient='index',columns=columns)\n",
    "    return Section,Frame\n",
    "\n",
    "def generate_query_points(Section, N,xpoints,zpoints,factor,arange,Frame):\n",
    "  \"\"\"Generate query points for strain calculation.\n",
    "\n",
    "    Args:\n",
    "        Section (dict): Section properties\n",
    "        N (int): Number of sections\n",
    "        xpoints (int): Number of x-points\n",
    "        zpoints (int): Number of z-points\n",
    "        factor (float): Sampling factor\n",
    "        arange (list): Contact radius range\n",
    "        Frame (DataFrame): Input frame with section data\n",
    "\n",
    "    Returns:\n",
    "        tuple: Various data structures for query points and properties\n",
    "  \"\"\"\n",
    "  FrameLarge_temp=[]\n",
    "  final_dict_ztoE=[]\n",
    "  final_dict_ztoH=[]\n",
    "  final_dict_ztonu = []\n",
    "  ZS=[]\n",
    "  H=[]\n",
    "  E=[]\n",
    "  NU = []\n",
    "\n",
    "  for i in range(N):\n",
    "    dict_z_to_E = {}\n",
    "    dict_z_to_H = {}\n",
    "    dict_z_to_nu={}\n",
    "    th=sum(Section[i]['Thickness'])+12\n",
    "    zs=np.power(np.linspace(np.sqrt(0.5),np.power(th,factor),zpoints),1/factor) #sampling near the surface\n",
    "    zs=np.sort(np.append(zs,np.append(np.cumsum(Section[i]['ThicknessSub'])+0.01,np.cumsum(Section[i]['ThicknessSub'])-0.01)))\n",
    "    ZS.append(zs)\n",
    "    E_per_section=np.zeros(len(zs))\n",
    "    H_per_section = np.zeros(len(zs))\n",
    "    nu_per_section = np.zeros(len(zs))\n",
    "    points_above_boundary=np.cumsum(Section[i]['ThicknessSub'])+0.01\n",
    "    points_below_boundary=np.cumsum(Section[i]['ThicknessSub'])-0.01\n",
    "    j=0\n",
    "\n",
    "    while j<=len(Section[i]['ModulusSub'])-1:\n",
    "      if j==0:\n",
    "        E_per_section[(zs<=points_below_boundary[j])]=Section[i]['ModulusSub'][j]\n",
    "        H_per_section[(zs<=points_below_boundary[j])]=Section[i]['ThicknessSub'][j]\n",
    "        nu_per_section[(zs<=points_below_boundary[j])]=Section[i]['PoissonSub'][j]\n",
    "        ind=0\n",
    "        j+=1\n",
    "      elif j>0 and j<len(Section[i]['ModulusSub'])-1:\n",
    "        E_per_section[(zs>=points_above_boundary[ind])&(zs<=points_below_boundary[j])]=Section[i]['ModulusSub'][j]\n",
    "        H_per_section[(zs>=points_above_boundary[ind])&(zs<=points_below_boundary[j])]=Section[i]['ThicknessSub'][j]\n",
    "        nu_per_section[(zs>=points_above_boundary[ind])&(zs<=points_below_boundary[j])]=Section[i]['PoissonSub'][j]\n",
    "        ind+=1\n",
    "        j+=1\n",
    "      elif j>=len(Section[i]['ModulusSub'])-1:\n",
    "        E_per_section[(zs>=points_above_boundary[ind])]=Section[i]['ModulusSub'][j]\n",
    "        H_per_section[(zs>=points_above_boundary[ind])]=-1\n",
    "        nu_per_section[(zs>=points_above_boundary[ind])]=Section[i]['PoissonSub'][j]\n",
    "        j+=1\n",
    "\n",
    "    for z,h in zip(zs,H_per_section):\n",
    "      dict_z_to_H[z] = h/100\n",
    "\n",
    "    final_dict_ztoH.append(dict_z_to_H)\n",
    "\n",
    "    for z,e in zip(zs,E_per_section):\n",
    "      dict_z_to_E[z]=e/100\n",
    "\n",
    "    final_dict_ztoE.append(dict_z_to_E)\n",
    "\n",
    "    for z,nu in zip(zs,nu_per_section):\n",
    "      dict_z_to_nu[z] = nu\n",
    "\n",
    "    final_dict_ztonu.append(dict_z_to_nu)\n",
    "\n",
    "    H.append(H_per_section)\n",
    "    E.append(E_per_section)\n",
    "    NU.append(nu_per_section)\n",
    "    xs = np.linspace(np.sqrt(0.5), np.sqrt(10), xpoints)**2\n",
    "    #radi=np.sort(random.sample(range(arange[0],arange[1]),apoints))\n",
    "    radi=[arange[0]]\n",
    "    Section[i]['z']=zs\n",
    "    Section[i]['x']=xs\n",
    "    Section[i]['a']=radi\n",
    "    FrameTemp=deepcopy(Frame.loc[i:i,:])\n",
    "    FrameTemp=pd.DataFrame(np.repeat(FrameTemp.values, len(radi)*len(zs)*len(xs), axis=0))\n",
    "    FrameTemp.columns = Frame.columns\n",
    "    res = np.matrix([[ii, j, k] for ii in radi\n",
    "                  for j in zs\n",
    "                  for k in xs])\n",
    "    FrameTemp.iloc[:,2:5]=res\n",
    "    FrameLarge_temp.append(FrameTemp)\n",
    "\n",
    "  FrameLarge_temp = pd.concat(FrameLarge_temp)\n",
    "  FrameLarge_temp=FrameLarge_temp.reset_index(drop=True)\n",
    "  FrameLarge_temp[['Displacement_Z', 'Displacement_H', 'Stress_Z', 'Stress_R', 'Stress_T', 'Stress_RZ', 'Strain_Z', 'Strain_R', 'Strain_T']]=0\n",
    "  return FrameLarge_temp, ZS, xs, E,NU,final_dict_ztoE,H,final_dict_ztoH,final_dict_ztonu\n",
    "\n",
    "def remove_strain_z(DF):\n",
    "    \"\"\"Remove sections with excessive strain values.\n",
    "\n",
    "    Args:\n",
    "        DF (DataFrame): Input dataframe with strain values\n",
    "\n",
    "    Returns:\n",
    "        tuple: (Filtered z-points, Filtered dataframe)\n",
    "    \"\"\"\n",
    "    ZS_new=[]\n",
    "    Length= DF[\"Structure\"].unique()\n",
    "\n",
    "    for structure in Length:\n",
    "        struct = int(structure) - 1\n",
    "        filtered = DF[DF[\"Structure\"] == structure]\n",
    "        inp = filtered.loc[:, [\"Strain_Z\"]] * 1e6\n",
    "        # Check if any Strain_Z value is greater than 2000\n",
    "        if (inp['Strain_Z'] >=1500).any():\n",
    "            DF = DF[DF[\"Structure\"] != structure]\n",
    "            continue\n",
    "        z_val = filtered['z'].unique()\n",
    "        ZS_new.append(z_val)\n",
    "\n",
    "    # normalizing\n",
    "    ZS_new=[ele/20 for ele in ZS_new]\n",
    "    return ZS_new,DF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "SCxQO4CDy11l",
   "metadata": {
    "executionInfo": {
     "elapsed": 1762,
     "status": "ok",
     "timestamp": 1750127986014,
     "user": {
      "displayName": "Urja Giridharan",
      "userId": "03202406529544037479"
     },
     "user_tz": 240
    },
    "id": "SCxQO4CDy11l"
   },
   "outputs": [],
   "source": [
    "Section_temp, Frame = generatesection(\n",
    "        SAMPLING_CONFIG['N_POINTS'], MATERIAL_CONFIG['N_MATERIALS'],\n",
    "        MATERIAL_CONFIG['MATERIAL_TYPES'], MATERIAL_CONFIG['SUBLAYER_MAX'],\n",
    "        MATERIAL_CONFIG['THICKNESS_RANGE'], MATERIAL_CONFIG['MODULUS_RANGE'],\n",
    "        SAMPLING_CONFIG['Z_POINTS'], SAMPLING_CONFIG['X_POINTS'],\n",
    "        MATERIAL_CONFIG['THICKNESS_INCREMENT'], MATERIAL_CONFIG['MODULUS_INCREMENT'],\n",
    "        MATERIAL_CONFIG['NU_RANGE'], SAMPLING_CONFIG['A_RANGE'],\n",
    "        SAMPLING_CONFIG['A_POINTS']\n",
    ")\n",
    "\n",
    "FrameLarge_temp, ZS, xs, E, NU, final_dict_ztoE, H, final_dict_ztoH, final_dict_ztonu = generate_query_points(\n",
    "        Section, SAMPLING_CONFIG['N_POINTS'], SAMPLING_CONFIG['X_POINTS'],\n",
    "        SAMPLING_CONFIG['Z_POINTS'], SAMPLING_CONFIG['FACTOR'],\n",
    "        SAMPLING_CONFIG['A_RANGE'], Frame\n",
    ")\n",
    "ZS, DF = remove_strain_z(FrameLarge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3ef4cdf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1750127989285,
     "user": {
      "displayName": "Urja Giridharan",
      "userId": "03202406529544037479"
     },
     "user_tz": 240
    },
    "id": "d3ef4cdf",
    "outputId": "4d613fea-c4b1-410d-b347-252d294ccda1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging in plot_dir plots, number 0\n"
     ]
    }
   ],
   "source": [
    "def convert_units(xs, zs):\n",
    "    xs_converted = xs * 2.54\n",
    "    ZS_converted = [i * 2.54 for i in zs]\n",
    "    xs = np.round(xs_converted, 2)\n",
    "    ZS_new = [np.round(zs, 2) for zs in ZS_converted]\n",
    "    return xs, ZS_new\n",
    "\n",
    "def build_pred_graph(batched_graph_test, final_y_pred):\n",
    "    pred_graph = {}\n",
    "    current_index = 0\n",
    "    for i in range(batched_graph_test.batch_size):\n",
    "        res_test = len(batched_graph_test[i].y)\n",
    "        pred_values = final_y_pred[current_index:current_index+res_test]\n",
    "        pred_graph[i] = pred_values\n",
    "        current_index += res_test\n",
    "    return pred_graph\n",
    "\n",
    "def setup_plotting():\n",
    "    # get unique number of experiment\n",
    "    plot_root = \"plots\"\n",
    "    if os.path.exists(plot_root):\n",
    "        avail_nums = os.listdir(plot_root)\n",
    "        avail_nums = [-1] + [int(d) for d in avail_nums if d.isdigit()]\n",
    "        exp_num = max(avail_nums) + 1\n",
    "    else:\n",
    "        exp_num = 0\n",
    "    exp_num = str(exp_num)\n",
    "    print(\"Logging in plot_dir {}, number {}\".format(plot_root, exp_num))\n",
    "\n",
    "\n",
    "    exp_plot_dir = os.path.join(plot_root, exp_num)\n",
    "\n",
    "    os.makedirs(exp_plot_dir, exist_ok=True)\n",
    "\n",
    "    log_path = os.path.join(plot_root, exp_num, \"log.txt\")\n",
    "    logging.basicConfig(filename=log_path,\n",
    "                    filemode='a',\n",
    "                    format='%(asctime)s | %(message)s',\n",
    "                    datefmt='%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO, force=True)\n",
    "    logging.info(\"generating plots for experiment {}\".format(exp_num))\n",
    "\n",
    "    return exp_plot_dir\n",
    "\n",
    "plot_dir = setup_plotting()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ab115f-b86a-4d98-8ae1-80a55ef0b587",
   "metadata": {
    "id": "a1ab115f-b86a-4d98-8ae1-80a55ef0b587"
   },
   "source": [
    "### NeuralNetwork Class Description\n",
    "\n",
    "The `NeuralNetwork` class implements a simple feed-forward neural network architecture for the Partial Neural Network (PNN) model:\n",
    "\n",
    "- **Input Layer:** Takes 5 input features representing material and geometric properties.\n",
    "- **Hidden Layers:** Four hidden layers, each with 90 neurons and ReLU activation functions, enable the network to capture complex nonlinear relationships in the data.\n",
    "- **Output Layer:** Outputs 3 values corresponding to the predicted strain components.\n",
    "- **Purpose:** This architecture is designed for regression tasks, mapping input features to physical response variables (such as strain) in layered material systems.\n",
    "\n",
    "The model is compact yet expressive, making it suitable for learning the underlying physics in the dataset while remaining computationally efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15fdf672-41f8-4481-98ee-cecc3fd94892",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1750131148535,
     "user": {
      "displayName": "Urja Giridharan",
      "userId": "03202406529544037479"
     },
     "user_tz": 240
    },
    "id": "15fdf672-41f8-4481-98ee-cecc3fd94892"
   },
   "outputs": [],
   "source": [
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    \"\"\"Simple feed-forward neural network implementation for PNN.\"\"\"\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        input_size = 5\n",
    "        hidden_size = 90\n",
    "        output_size = 3\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.layers(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40aa98c7-5f58-4c6a-99dd-1c5133767296",
   "metadata": {
    "id": "40aa98c7-5f58-4c6a-99dd-1c5133767296"
   },
   "source": [
    " Load Model Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "rtmMBW8kzeXy",
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1750131622192,
     "user": {
      "displayName": "Urja Giridharan",
      "userId": "03202406529544037479"
     },
     "user_tz": 240
    },
    "id": "rtmMBW8kzeXy"
   },
   "outputs": [],
   "source": [
    "model_path = r'/content/drive/MyDrive/Graph_Neural_Network/PIML-main/models/model_epoch_14699.pt'\n",
    "model = NeuralNetwork()\n",
    "model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a802253-d5ef-4ae9-8857-014d5408cf63",
   "metadata": {
    "id": "9a802253-d5ef-4ae9-8857-014d5408cf63"
   },
   "source": [
    "## Model Evaluation\n",
    "\n",
    "This section evaluates the trained PNN model's performance:\n",
    "\n",
    "### Evaluation Process\n",
    "1. Loads the trained model checkpoint\n",
    "2. Runs inference on test data\n",
    "3. Calculates multiple metrics:\n",
    "   - Mean Squared Error (MSE) for each strain component\n",
    "   - Mean Absolute Error (MAE) for each strain component\n",
    "   - Mean Absolute Percentage Error (MAPE) for each strain component\n",
    "4. Logs results for analysis\n",
    "\n",
    "### Metrics Explanation\n",
    "- MSE: Measures average squared difference between predictions and actual values\n",
    "- MAE: Measures average absolute difference\n",
    "- MAPE: Measures relative error as a percentage\n",
    "- Each metric is calculated separately for:\n",
    "  - Vertical strain (εz)\n",
    "  - Radial strain (εr)\n",
    "  - Tangential strain (εθ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f0464b7-821b-454d-908e-00b8b4149071",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 55,
     "status": "ok",
     "timestamp": 1750131709261,
     "user": {
      "displayName": "Urja Giridharan",
      "userId": "03202406529544037479"
     },
     "user_tz": 240
    },
    "id": "2f0464b7-821b-454d-908e-00b8b4149071",
    "outputId": "55610cdc-835e-4406-9802-bbf39f9c3602"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE_Z: 2623.639404296875, MAE_Z: 19.44541358947754, MSE_R: 332.11273193359375, MAE_R: 8.102648735046387, MSE_T: 479.84210205078125, MAE_T: 0.7006247043609619, MAPE_Z: 0.5841040015220642, MAPE_R: 0.721420407295227, MAPE_T: 0.7006247043609619\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    batched_graph_test = batched_graph_test.cpu()\n",
    "    model=model.cpu()\n",
    "    test_outputs = model(batched_graph_test.x)\n",
    "    predicted_values = test_outputs.numpy()\n",
    "\n",
    "mse_z = mean_squared_error( batched_graph_test.y[:, 0].cpu().detach().numpy(), predicted_values[:, 0])\n",
    "mse_r = mean_squared_error( batched_graph_test.y[:, 1].cpu().detach().numpy(), predicted_values[:, 1])\n",
    "mse_t = mean_squared_error( batched_graph_test.y[:, 2].cpu().detach().numpy(), predicted_values[:, 2])\n",
    "mae_z = mean_absolute_error( batched_graph_test.y[:, 0].cpu().detach().numpy(), predicted_values[:, 0])\n",
    "mae_r = mean_absolute_error(batched_graph_test.y[:, 1].cpu().detach().numpy(), predicted_values[:, 1])\n",
    "mae_t = mean_absolute_error(batched_graph_test.y[:, 2].cpu().detach().numpy(), predicted_values[:, 2])\n",
    "\n",
    "mape_z = mean_absolute_percentage_error(batched_graph_test.y[:, 0].cpu().detach().numpy(), predicted_values[:, 0])\n",
    "mape_r = mean_absolute_percentage_error(batched_graph_test.y[:, 1].cpu().detach().numpy(), predicted_values[:, 1])\n",
    "mape_t = mean_absolute_percentage_error(batched_graph_test.y[:, 2].cpu().detach().numpy(), predicted_values[:, 2])\n",
    "\n",
    "logging.info(f\"MSE_Z: {mse_z}, MAE_Z: {mae_z}, MSE_R: {mse_r}, MAE_R: {mae_r}, MSE_T: {mse_t}, MAE_T: {mape_t}, MAPE_Z: {mape_z}, MAPE_R: {mape_r}, MAPE_T: {mape_t}\")\n",
    "print(f\"MSE_Z: {mse_z}, MAE_Z: {mae_z}, MSE_R: {mse_r}, MAE_R: {mae_r}, MSE_T: {mse_t}, MAE_T: {mape_t}, MAPE_Z: {mape_z}, MAPE_R: {mape_r}, MAPE_T: {mape_t}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efefde7d",
   "metadata": {
    "id": "efefde7d"
   },
   "source": [
    "## Visualization\n",
    "\n",
    "This section contains functions for visualizing model predictions and results:\n",
    "\n",
    "### plot_actual_vs_predicted_PNN()\n",
    "Creates scatter plots comparing actual vs predicted values:\n",
    "- Generates separate plots for each strain component\n",
    "- Includes perfect prediction line (y=x)\n",
    "- Uses consistent styling and labeling\n",
    "- Saves plots to specified directory\n",
    "\n",
    "### plot_heatmaps()\n",
    "Generates heatmaps of strain distributions:\n",
    "- Shows strain distribution in (x,z) space\n",
    "- Creates separate plots for:\n",
    "  - Actual strain values\n",
    "  - Predicted strain values\n",
    "- Includes:\n",
    "  - Color bars with strain values\n",
    "  - Proper axis labels and units\n",
    "  - Consistent styling and formatting\n",
    "- Saves high-resolution plots for publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "FZEnQMUdo1QB",
   "metadata": {
    "executionInfo": {
     "elapsed": 52,
     "status": "ok",
     "timestamp": 1750131730889,
     "user": {
      "displayName": "Urja Giridharan",
      "userId": "03202406529544037479"
     },
     "user_tz": 240
    },
    "id": "FZEnQMUdo1QB"
   },
   "outputs": [],
   "source": [
    "plot_dir = '/content/drive/MyDrive/Graph_Neural_Network/PIML-main/plots'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c7b2532c",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1750131747161,
     "user": {
      "displayName": "Urja Giridharan",
      "userId": "03202406529544037479"
     },
     "user_tz": 240
    },
    "id": "c7b2532c"
   },
   "outputs": [],
   "source": [
    "def plot_actual_vs_predicted_PNN(batched_graph_test, predicted_values, plot_dir=None):\n",
    "    \"\"\"Plot actual vs predicted strain values.\n",
    "\n",
    "    Args:\n",
    "        batched_graph_test: Test data\n",
    "        predicted_values: Model predictions\n",
    "        plot_dir (str, optional): Directory to save plots\n",
    "    \"\"\"\n",
    "    sns.set_style(\"darkgrid\")\n",
    "    labels = ['z', 'r', 't']\n",
    "    for i, label in enumerate(labels):\n",
    "        plt.scatter(batched_graph_test.y[:, i].cpu().detach().numpy(), predicted_values[:, i])\n",
    "        p1 = max(batched_graph_test.y[:, i].cpu().detach().numpy().max(), predicted_values[:, i].max())\n",
    "        p2 = min(batched_graph_test.y[:, i].cpu().detach().numpy().min(), predicted_values[:, i].min())\n",
    "        plt.plot([p2, p1], [p2, p1], color='black', linestyle='--')\n",
    "        plt.xlabel(f'Actual $\\mu\\epsilon_{label}$', fontsize=12)\n",
    "        plt.ylabel(f'Predicted $\\mu\\epsilon_{label}$', fontsize=12)\n",
    "        plt.title(f'Actual vs Predicted in $\\mu\\epsilon_{label}$', fontsize=12)\n",
    "        plt.tight_layout()\n",
    "        if plot_dir:\n",
    "            plt.savefig(os.path.join(plot_dir, f\"actual_vs_pred_{label}_pnn.png\"))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75ade6c9-340f-4b8d-a105-4508ce1dcea1",
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1750131838022,
     "user": {
      "displayName": "Urja Giridharan",
      "userId": "03202406529544037479"
     },
     "user_tz": 240
    },
    "id": "75ade6c9-340f-4b8d-a105-4508ce1dcea1"
   },
   "outputs": [],
   "source": [
    "def plot_heatmaps(ZS_new, xs, batched_graph_test, pred_graph, plot_dir=None, test_struct=0, test_g_struct=0):\n",
    "    \"\"\"Generate heatmaps of strain distributions.\n",
    "\n",
    "    Args:\n",
    "        ZS_new: Z-coordinates\n",
    "        xs: X-coordinates\n",
    "        batched_graph_test: Test data\n",
    "        pred_graph: Predicted values\n",
    "        plot_dir (str, optional): Directory to save plots\n",
    "        test_struct (int): Test structure index\n",
    "        test_g_struct (int): Test graph structure index\n",
    "    \"\"\"\n",
    "    # Strain_Z actual\n",
    "    sns.set_theme(rc={'figure.figsize':(20,10)}, font_scale=3)\n",
    "    z = np.array(ZS_new[test_struct])\n",
    "    response = 'Strain_Z'\n",
    "    A_prep = np.reshape(batched_graph_test[test_g_struct].y[:,0], (len(ZS_new[test_struct]), len(xs)))\n",
    "    heatmap = sns.heatmap(A_prep, linewidths=.5, xticklabels=xs, yticklabels=-z, cbar_kws={'label': 'Strain (µε)'})\n",
    "    colorbar = heatmap.collections[0].colorbar\n",
    "    colorbar.ax.yaxis.label.set_size(30)\n",
    "    plt.xlabel('x (cm)', fontsize=30)\n",
    "    plt.ylabel('z (cm)', fontsize=30)\n",
    "    plt.title(r'$\\epsilon_z$')\n",
    "    plt.xticks(fontsize=30)\n",
    "    plt.yticks(fontsize=30)\n",
    "    plt.tight_layout()\n",
    "    if plot_dir:\n",
    "        plt.savefig(os.path.join(plot_dir, \"PNN_strain_z_heatmap_struct0_actual.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # Strain_Z predicted\n",
    "    sns.set_theme(rc={'figure.figsize':(20,10)}, font_scale=3)\n",
    "    A_bar = np.reshape(pred_graph[test_struct][:,0], (len(ZS_new[test_struct]), len(xs)))\n",
    "    heatmap = sns.heatmap(A_bar, linewidths=.5, xticklabels=xs, yticklabels=-z, cbar_kws={'label': 'Strain (µε)'})\n",
    "    colorbar = heatmap.collections[0].colorbar\n",
    "    colorbar.ax.yaxis.label.set_size(30)\n",
    "    plt.xlabel('x (cm)', fontsize=30)\n",
    "    plt.ylabel('z (cm)', fontsize=30)\n",
    "    plt.title(r'$\\epsilon_z$')\n",
    "    plt.xticks(fontsize=30)\n",
    "    plt.yticks(fontsize=30)\n",
    "    plt.tight_layout()\n",
    "    if plot_dir:\n",
    "        plt.savefig(os.path.join(plot_dir, \"PNN_strain_z_heatmap_struct0_pred.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # Strain_R actual\n",
    "    sns.set_theme(rc={'figure.figsize':(20,10)}, font_scale=3)\n",
    "    response = 'Strain_R'\n",
    "    A_prep = np.reshape(batched_graph_test[test_g_struct].y[:,1], (len(ZS_new[test_struct]), len(xs)))\n",
    "    heatmap = sns.heatmap(A_prep, linewidths=.5, xticklabels=xs, yticklabels=-z, cbar_kws={'label': 'Strain (µε)'})\n",
    "    colorbar = heatmap.collections[0].colorbar\n",
    "    colorbar.ax.yaxis.label.set_size(30)\n",
    "    plt.xlabel('x (cm)', fontsize=30)\n",
    "    plt.ylabel('z (cm)', fontsize=30)\n",
    "    plt.title(r'$\\epsilon_r$')\n",
    "    plt.xticks(fontsize=30)\n",
    "    plt.yticks(fontsize=30)\n",
    "    plt.tight_layout()\n",
    "    if plot_dir:\n",
    "        plt.savefig(os.path.join(plot_dir, \"PNN_strain_r_heatmap_struct0_actual.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # Strain_R predicted\n",
    "    sns.set_theme(rc={'figure.figsize':(20,10)}, font_scale=3)\n",
    "    A_bar = np.reshape(pred_graph[test_struct][:,1], (len(ZS_new[test_struct]), len(xs)))\n",
    "    heatmap = sns.heatmap(A_bar, linewidths=.5, xticklabels=xs, yticklabels=-z, cbar_kws={'label': 'Strain (µε)'})\n",
    "    colorbar = heatmap.collections[0].colorbar\n",
    "    colorbar.ax.yaxis.label.set_size(30)\n",
    "    plt.xlabel('x (cm)', fontsize=30)\n",
    "    plt.ylabel('z (cm)', fontsize=30)\n",
    "    plt.title(r'$\\epsilon_r$')\n",
    "    plt.xticks(fontsize=30)\n",
    "    plt.yticks(fontsize=30)\n",
    "    plt.tight_layout()\n",
    "    if plot_dir:\n",
    "        plt.savefig(os.path.join(plot_dir, \"PNN_strain_r_heatmap_struct0_pred.png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82bdb35e",
   "metadata": {
    "executionInfo": {
     "elapsed": 1548,
     "status": "ok",
     "timestamp": 1750131839765,
     "user": {
      "displayName": "Urja Giridharan",
      "userId": "03202406529544037479"
     },
     "user_tz": 240
    },
    "id": "82bdb35e"
   },
   "outputs": [],
   "source": [
    "# Convert units\n",
    "xs, ZS_new = convert_units(xs, ZS_new)\n",
    "\n",
    "# Build prediction graph\n",
    "pred_graph = build_pred_graph(batched_graph_test, predicted_values)\n",
    "\n",
    "# Plot heatmaps\n",
    "plot_heatmaps(ZS_new, xs, batched_graph_test, pred_graph, plot_dir=plot_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "u5KTARD9nip0",
   "metadata": {
    "executionInfo": {
     "elapsed": 893,
     "status": "ok",
     "timestamp": 1750131840684,
     "user": {
      "displayName": "Urja Giridharan",
      "userId": "03202406529544037479"
     },
     "user_tz": 240
    },
    "id": "u5KTARD9nip0"
   },
   "outputs": [],
   "source": [
    "plot_actual_vs_predicted_PNN(batched_graph_test, predicted_values, plot_dir=plot_dir)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1QXBGDEgXzHIziuW4fRaxW_6mYaMjno6p",
     "timestamp": 1750126774478
    }
   ]
  },
  "kernelspec": {
   "display_name": "gnn_kernel",
   "language": "python",
   "name": "gnn_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
